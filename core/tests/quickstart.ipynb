{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c3f49f",
   "metadata": {},
   "source": [
    "#### Install dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592aef6b523d1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install autoflow-ai==0.0.1.dev7\n",
    "%pip install dotenv sqlalchemy ipywidgets pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d5be6",
   "metadata": {},
   "source": [
    "#### Configure environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8163102a04a2ffde",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create .env file, then edit your .env, for example:\n",
    "# $ cat .env\n",
    "# DATABASE_URL='mysql+pymysql://root@localhost:4000/test'\n",
    "# OPENAI_API_KEY='your_openai_api_key'\n",
    "%cp .env.example .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6cdb4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38fde21",
   "metadata": {},
   "source": [
    "#### Init Autoflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f43a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from autoflow import Autoflow\n",
    "# from google.colab import userdata\n",
    "# db_engine = create_engine(userdata.get('DATABASE_URL'))\n",
    "\n",
    "db_engine = create_engine(os.getenv(\"DATABASE_URL\"))\n",
    "af = Autoflow(db_engine=db_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afea9b7",
   "metadata": {},
   "source": [
    "#### Create knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1ff63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeBase(id=UUID('655b6cf3-8b30-4839-ba8b-5ed3c502f30e'), name='New KB', index_methods=[<IndexMethod.VECTOR_SEARCH: 'VECTOR_SEARCH'>, <IndexMethod.KNOWLEDGE_GRAPH: 'KNOWLEDGE_GRAPH'>], description='This is a knowledge base for testing', chunking_config=GeneralChunkingConfig(mode=<ChunkingMode.GENERAL: 'general'>, chunk_size=1200, chunk_overlap=200, paragraph_separator='\\n\\n\\n'), data_sources=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "from autoflow.schema import IndexMethod\n",
    "from autoflow.llms.chat_models import ChatModel\n",
    "from autoflow.llms.embeddings import EmbeddingModel\n",
    "\n",
    "chat_model = ChatModel(\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "embed_model = EmbeddingModel(\n",
    "    model_name=\"text-embedding-3-small\",\n",
    "    dimensions=1536,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Create Knowledge base\n",
    "kb = af.create_knowledge_base(\n",
    "    id=UUID('655b6cf3-8b30-4839-ba8b-5ed3c502f30e'),\n",
    "    name=\"New KB\",\n",
    "    description=\"This is a knowledge base for testing\",\n",
    "    index_methods=[IndexMethod.VECTOR_SEARCH, IndexMethod.KNOWLEDGE_GRAPH],\n",
    "    chat_model=chat_model,\n",
    "    embedding_model=embed_model,\n",
    ")\n",
    "kb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc2d80",
   "metadata": {},
   "source": [
    "#### Import documents from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbdac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f729326f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "kb.import_documents_from_files(\n",
    "    files=[\n",
    "        Path(current_dir) / \"fixtures\" / \"tidb-overview.md\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "259ad7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7382136171419582,\n",
       "  'What is TiDB Self-Managed Key features\\n<!-- Localization note for TiDB:\\n- English: use distributed SQL, and start to emphasize HTAP\\n- Chinese: can keep \"NewSQL\" and emphasize one-stop real-time HTAP (\"一栈式实时 HTAP\")\\n- Japanese: use NewSQL because it is well-recognized\\n-->\\nTiDB (/\\'taɪdiːbi:/, \"Ti\" stands for Titanium) is an open-source distributed SQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. It is MySQL compatible and features horizontal scalability, strong consistency, and high availability. The goal of TiDB is to provide users with a one-stop database solution that covers OLTP (Online Transactional Processing), OLAP (Online Analytical Processing), and HTAP services. TiDB is suitable for various use cases that require high availability and strong consistency with large-scale data.\\nTiDB Self-Managed is a product option of TiDB, where users or organizations can deploy and manage TiDB on their own infrastructure with complete flexibility. With TiDB Self-Managed, you can enjoy the power of open source, distributed SQL while retaining full control over your environment.\\nThe following video introduces key features of TiDB.\\n\\n- **Easy horizontal scaling**\\nThe TiDB architecture design separates computing from storage, letting you scale out or scale in the computing or storage capacity online as needed. The scaling process is transparent to application operations and maintenance staff.\\n- **Financial-grade high availability**\\nData is stored in multiple replicas, and the Multi-Raft protocol is used to obtain the transaction log. A transaction can only be committed when data has been successfully written into the majority of replicas. This guarantees strong consistency and availability when a minority of replicas go down. You can configure the geographic location and number of replicas as needed to meet different disaster tolerance levels.\\n- **Real-time HTAP**\\nTiDB provides two storage engines: TiKV, a row-based storage engine, and TiFlash, a columnar storage engine. TiFlash uses the Multi-Raft Learner protocol to replicate data from TiKV in real time, ensuring consistent data between the TiKV row-based storage engine and the TiFlash columnar storage engine. TiKV and TiFlash can be deployed on different machines as needed to solve the problem of HTAP resource isolation.\\n- **Cloud-native distributed database**\\nTiDB is a distributed database designed for the cloud, providing flexible scalability, reliability, and security on the cloud platform. Users can elastically scale TiDB to meet the requirements of their changing workloads. In TiDB, each piece of data has at least 3 replicas, which can be scheduled in different cloud availability zones to tolerate the outage of a whole data center. TiDB Operator helps manage TiDB on Kubernetes and automates tasks related to operating the TiDB cluster, making TiDB easier to deploy on any cloud that provides managed Kubernetes. TiDB Cloud, the fully-managed TiDB service, is the easiest, most economical, and most resilient way to unlock the full power of TiDB in the cloud, allowing you to deploy and run TiDB clusters with just a few clicks.\\n- **Compatible with the MySQL protocol and MySQL ecosystem**\\nTiDB is compatible with the MySQL protocol, common features of MySQL, and the MySQL ecosystem. To migrate applications to TiDB, you do not need to change a single line of code in many cases, or only need to modify a small amount of code. In addition, TiDB provides a series of data migration tools to help easily migrate application data into TiDB.'),\n",
       " (0.7380405884397471,\n",
       "  'What is TiDB Self-Managed See also\\n- TiDB Architecture\\n- TiDB Storage\\n- TiDB Computing\\n- TiDB Scheduling')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = kb.search_documents(\n",
    "    query=\"What is TiDB?\",\n",
    "    similarity_top_k=2,\n",
    ")\n",
    "[(c.score, c.chunk.text) for c in result.chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc5bc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huohao/autoflow/.venv/lib/python3.11/site-packages/sqlmodel/orm/session.py:66: SAWarning: SELECT statement has a cartesian product between FROM element(s) \"candidates\" and FROM element \"entities_655b6cf3-8b30-4839-ba8b-5ed3c502f30e\".  Apply join condition(s) between each element to resolve.\n",
      "  results = super().execute(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['TiDB -> TiDB Self-Managed is a product option of TiDB that allows for deployment and management on user infrastructure. -> TiDB Self-Managed',\n",
       " 'TiDB -> TiDB uses TiKV as its row-based storage engine to ensure consistent data storage. -> TiKV',\n",
       " 'TiDB -> TiDB uses TiFlash as its columnar storage engine to replicate data from TiKV in real time. -> TiFlash',\n",
       " 'TiDB -> TiDB employs the Multi-Raft protocol to manage transaction logs and ensure strong consistency across replicas. -> Multi-Raft Protocol',\n",
       " 'TiDB -> TiDB Operator facilitates the management of TiDB on Kubernetes, automating cluster operations. -> TiDB Operator',\n",
       " 'TiDB -> TiDB Cloud is a fully-managed service that simplifies the deployment and operation of TiDB clusters in the cloud. -> TiDB Cloud',\n",
       " 'TiDB -> TiDB is built upon a specific architecture that defines its structure and functionality. -> TiDB Architecture',\n",
       " 'TiDB -> TiDB utilizes a storage component to manage data persistence and retrieval. -> TiDB Storage',\n",
       " 'TiDB -> TiDB incorporates computing capabilities to process queries and perform data operations. -> TiDB Computing',\n",
       " 'TiDB -> TiDB employs scheduling mechanisms to efficiently manage task execution and resource allocation. -> TiDB Scheduling']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg = kb.search_knowledge_graph(\n",
    "    query=\"What is TiDB?\",\n",
    ")\n",
    "[(r.rag_description) for r in kg.relationships]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
