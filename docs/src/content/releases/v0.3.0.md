# Release Notes for v0.3.0

## Highlights

- Rename project to `autoflow`
- Multiple Knowledge Bases support
- Support new LLM providers
  - [OpenRouter](../llm.mdx#openrouter)
  - [ZhipuAI BigModel](../llm.mdx#zhipuai-bigmodel)
  - [Ollama](../llm.mdx#ollama)
- Support new embedding models providers
  - [Ollama](../embedding-model.mdx#ollama)
  - Support [OpenAI Like](../embedding-model.mdx#openai-like) embedding model providers
    - [ZhipuAI BigModel](../embedding-model.mdx#zhipuai-bigmodel)

## Breaking Changes

- [Knowledge Base](/docs/knowledge-base)
    - Deprecate old datasource management. [Manual migration](#manual-migration) is required.
    - Support different Embedding Models for each KB
    - Individual vector index and knowledge graph index for each KB
    - Move vector search and graph search API to knowledge base level
    - Move index progress and error retries to knowledge base

## Improvements

- Support create chat engine from default config


## Manual Migration

### Migrating from v0.2.x to v0.3.0

In previous versions, there was no concept of Knowledge Base, and Autoflow stored index data in the following tables:

- `chunks`
- `entities`
- `relationships`

In the v0.3.0, index data will be stored separately in tables corresponding to each knowledge base: 

- `chunks_{knowledge_base_id}`
- `entities_{knowledge_base_id}`
- `relationships_{knowledge_base_id}`

After upgrading to v0.3.0, the data in the original tables will be **preserved**. If you want to migrate the old data to the new knowledge base, you can follow the steps below:

1. Follow the [Upgrade](../deploy-with-docker.mdx#upgrade) guide to upgrade the application to v0.3.0.
2. Create a new knowledge base in the admin panel.
3. Connect to your database using TiDB Serverless Web Console or using mysql client.
4. Obtain the new knowledge base ID:

    ```sql
    SELECT id, name FROM knowledge_bases;
    ```

5. Replace the `{knowledge_base_id}` in the following SQL scripts with the new knowledge base ID and execute them:

    ```sql
    BEGIN;

    INSERT INTO knowledge_base_datasources (knowledge_base_id, data_source_id)
    SELECT {knowledge_base_id}, id
    FROM data_sources
    WHERE id NOT IN (SELECT data_source_id FROM knowledge_base_datasources);

    UPDATE documents SET knowledge_base_id = {knowledge_base_id} WHERE knowledge_base_id IS NULL;

    INSERT INTO chunks_{knowledge_base_id} (id, hash, text, meta, embedding, document_id, relations, source_uri, index_status, index_result, created_at, updated_at)
    SELECT id, hash, text, meta, embedding, document_id, relations, source_uri, index_status, index_result, created_at, updated_at
    FROM chunks;

    INSERT INTO entities_{knowledge_base_id} (id, name, description, meta, entity_type, synopsis_info, description_vec, meta_vec)
    SELECT id, name, description, meta, entity_type, synopsis_info, description_vec, meta_vec
    FROM entities;

    INSERT INTO relationships_{knowledge_base_id} (id, description, meta, weight, source_entity_id, target_entity_id, last_modified_at, document_id, chunk_id, description_vec)
    SELECT id, description, meta, weight, source_entity_id, target_entity_id, last_modified_at, document_id, chunk_id, description_vec
    FROM relationships;

    COMMIT;
    ```
