# Release Notes for v0.5.0 (Candidate Release)

## Highlights

- Knowledge Base supports configuring text chunking setting
- Add Bedrock Converse support
- Improve Chat Engine settings
  - Support selecting multiple Knowledge Bases
  - Support switches to control whether to use Further Questions and Rewrite Question feature
  - Support more options to control the vector search retrieval
- Support updating LLM / Embedding Model / Reranker Model configuration
- Support reindex single document

## Improvements

- Modify the default `context_window` of Ollama LLM provider to 4096 tokens. (Too large context window for local LLM may cost more GPU memory, too small context window may cause insufficient context tokens error)

## Breaking Changes

- The new version uses [RichPromptTemplate](https://docs.llamaindex.ai/en/stable/examples/prompts/rich_prompt_template_features/) to manage prompt templates, after upgrading, you need to modify the old placeholders in the **Answer Question** prompt template like:
  - `<<context_str>>` -> `{{context_str}}`
  - `<<query_str>>` -> `{{query_str}}`
